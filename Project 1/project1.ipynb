{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score,log_loss\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import save,load,save_plot,plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (a) : Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'rec.autos',\n",
    "              'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "train_data = {}\n",
    "dic = {}\n",
    "for i in range(len(categories)):\n",
    "    temp_data = fetch_20newsgroups(subset='train', categories=categories[i:i+1], shuffle=True,\n",
    "                                   random_state=42, remove=('headers','footers','quotes'))\n",
    "    dic[i] = len(temp_data.data)\n",
    "train_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True,\n",
    "                                random_state=42, remove=('headers','footers','quotes'))\n",
    "keys = []\n",
    "vals = []\n",
    "\n",
    "for key,val in dic.items():\n",
    "    keys.append(key)\n",
    "    vals.append(val)\n",
    "    \n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plotList = plt.bar(keys, vals, align='center', alpha=0.5)\n",
    "color = ['r', 'g', 'b', 'grey', 'magenta', 'brown', 'pink', 'purple']\n",
    "for i in range(len(keys)):\n",
    "    plotList[i].set_color(color[i])\n",
    "plt.xlabel('Categories',fontsize=15)\n",
    "plt.xticks(keys, train_data.target_names, rotation=-45,fontsize=15)\n",
    "plt.ylabel('Number of Records',fontsize=15)\n",
    "plt.title('Histogram')\n",
    "save_plot(fig,filename='histogram',directory='results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (b) : Calculating TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.graphics','comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware','comp.sys.mac.hardware',\n",
    "             'rec.autos','rec.motorcycles','rec.sport.baseball','rec.sport.hockey']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True,\n",
    "                                  random_state=42, remove=('headers','footers','quotes'))\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True,\n",
    "                                 random_state=42, remove=('headers','footers','quotes'))\n",
    "print(\"Length of training data ==>\", len(twenty_train.data))\n",
    "print(\"Length of testing data ==>\", len(twenty_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initParams(tfidf_min_df):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    analyzer = CountVectorizer().build_analyzer()\n",
    "    #Use token_pattern parameter with analyzer='word' if no stemming and want to remove words that are only numbers.\n",
    "    vectorizer = CountVectorizer(stop_words='english', min_df=tfidf_min_df, max_df=0.8, analyzer=stemmedWords,\n",
    "                                 strip_accents='ascii', token_pattern='\\w*[a-zA-Z]')\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    return [stemmer,analyzer,vectorizer,tfidf_transformer]\n",
    "\n",
    "def getTfidf(vectorizer,tfidf_transformer,data,isTraining=True):\n",
    "    if(isTraining):\n",
    "        count_data = vectorizer.fit_transform(data)\n",
    "        tfidf_data = tfidf_transformer.fit_transform(count_data)\n",
    "    else:\n",
    "        count_data = vectorizer.transform(data)\n",
    "        tfidf_data = tfidf_transformer.transform(count_data)        \n",
    "    return tfidf_data\n",
    "\n",
    "def stemmedWords(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "stemmer,analyzer,vectorizer,tfidf_transformer = initParams(tfidf_min_df=2)\n",
    "\n",
    "load_from_previous = False\n",
    "\n",
    "if(load_from_previous):\n",
    "    training_data = load('tfidf_training')\n",
    "    testing_data = load('tfidf_testing')\n",
    "else:\n",
    "    training_data = getTfidf(vectorizer,tfidf_transformer,twenty_train.data)\n",
    "    testing_data = getTfidf(vectorizer,tfidf_transformer,twenty_test.data,isTraining=False)\n",
    "    save(training_data,'tfidf_training')\n",
    "    save(testing_data,'tfidf_testing')\n",
    "\n",
    "print('Shape of Training Data ==>', training_data.shape)\n",
    "print('Shape of Testing Data ==>', testing_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_data.nnz / float(training_data.shape[0]))\n",
    "min_df='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (c) : Calculating TF-ICF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, remove=('headers','footers','quotes'))\n",
    "categories = list(train_all.target_names)\n",
    "category_train = {key:'\\n '.join([train_all.data[i] for i in range(len(train_all.data)) \n",
    "                                  if train_all.target[i] == categories.index(key)]) for key in categories}\n",
    "_,_,tfidf_vectorizer,tfidf_transformer = initParams(tfidf_min_df=1)\n",
    "keys,values=[],[]\n",
    "for k,v in category_train.items():\n",
    "    keys.append(k)\n",
    "    values.append(v)\n",
    "\n",
    "tficf_data = getTfidf(tfidf_vectorizer,tfidf_transformer,values)\n",
    "save(tficf_data,'tficf_data')\n",
    "\n",
    "\n",
    "def topTfidfFeats(row, features, top_n=10):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "def topFeatsInDoc(Xtr, features, row_id, top_n=10):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return topTfidfFeats(row, features, top_n)\n",
    "\n",
    "def plotTopTfidfFeatures(df):\n",
    "    ''' Plot the data frames returned by the function plot_tfidf_classfeats(). '''\n",
    "    fig = plt.figure(figsize=(14, 11), facecolor=\"w\")\n",
    "    x = np.arange(len(df))\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.set_xlabel(\"Mean Tf-Idf Score\", labelpad=16, fontsize=18)\n",
    "    ax.set_title(\"label = \" + str(df.label), fontsize=20)\n",
    "    ax.ticklabel_format(axis='x', style='sci', scilimits=(-2,2))\n",
    "    ax.barh(x, df.tfidf, align='center', color='#3F5D7D')\n",
    "    ax.set_yticks(x)\n",
    "    ax.set_ylim([-1, x[-1]+1])\n",
    "    ax.set_xticks(np.arange(0,1,0.1))\n",
    "    ax.set_xlim([0,1])\n",
    "    yticks = ax.set_yticklabels(df.feature, fontsize=18)\n",
    "    save_plot(fig,filename=df.label,directory='results/imp_words')\n",
    "    \n",
    "for i in range(len(keys)):\n",
    "    df = topFeatsInDoc(tficf_data, tfidf_vectorizer.get_feature_names(), i, top_n=10)\n",
    "    df.label = keys[i]\n",
    "    plotTopTfidfFeatures(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (d) : Feature Selection (Dimensionality Reduction)\n",
    "Reduce the dimentionality of the corpus using the following two methods.\n",
    "1. Latent Semantic Indexing (LSI)\n",
    "2. Non-negative Matrix Factorization (NMF)\n",
    "Compare the results for both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_previous = False\n",
    "#LSI\n",
    "def getLSI(data,lsi=None,isTrain=True):\n",
    "    if(isTrain):\n",
    "        lsi = TruncatedSVD(n_components=50, n_iter=7, random_state=42)\n",
    "        lsi_data = lsi.fit_transform(data)\n",
    "    else:\n",
    "        lsi_data = lsi.transform(data)\n",
    "    return lsi,lsi_data\n",
    "\n",
    "if(load_from_previous):\n",
    "    model = load('lsi_model_'+min_df)\n",
    "    lsi = model['model']\n",
    "    lsi_train = model['train']\n",
    "else:    \n",
    "    lsi,lsi_train = getLSI(training_data)\n",
    "    _,lsi_test = getLSI(testing_data,lsi,isTrain=False)\n",
    "    save({'model':lsi,'train':lsi_train,'test':lsi_test},'lsi_model_'+min_df)\n",
    "print('Shape of LSI Training Data ==>', lsi_train.shape)\n",
    "\n",
    "#NMF\n",
    "def getNMF(data,nmf=None,isTrain=True):\n",
    "    if(isTrain):\n",
    "        nmf = NMF(n_components=50, init='random', random_state=42)\n",
    "        nmf_data = nmf.fit_transform(data)\n",
    "    else:\n",
    "        nmf_data = nmf.transform(data)\n",
    "    return nmf,nmf_data\n",
    "\n",
    "if(load_from_previous):\n",
    "    model = load('nmf_model_'+min_df)\n",
    "    nmf = model['model']\n",
    "    nmf_train = model['train']\n",
    "else:    \n",
    "    nmf,nmf_train = getNMF(training_data)\n",
    "    _,nmf_test = getNMF(testing_data,nmf,isTrain=False)\n",
    "    save({'model':nmf,'train':nmf_train,'test':nmf_test},'nmf_model_'+min_df)\n",
    "print('Shape of NMF Training Data ==>', nmf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (e) : Binary Classification using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_from_previous = True\n",
    "train_target = np.array((map(lambda x : 0 if x<4 else 1,twenty_train.target)))\n",
    "target_names = ['Computer Technology','Recreational Activity']\n",
    "test_target = np.array((map(lambda x : 0 if x<4 else 1,twenty_test.target)))\n",
    "#twenty_test.target_names = ['Computer Technology','Recreational Activity']\n",
    "\n",
    "if(load_from_previous):\n",
    "    lsi_test = load('lsi_model_'+min_df)['test']\n",
    "    nmf_test = load('nmf_model_'+min_df)['test']\n",
    "else:\n",
    "    _,lsi_test = getLSI(testing_data,lsi,isTrain=False)\n",
    "    _,nmf_test = getNMF(testing_data,nmf,isTrain=False)\n",
    "\n",
    "def runSVM(lsi_train,nmf_train,train_target,lsi_test,nmf_test,test_target,C=1000):\n",
    "    global min_df\n",
    "    fig=plt.figure()\n",
    "    print('---------------LSI RESULTS---------------')\n",
    "    clf = svm.SVC(kernel='linear',C=C,random_state=42,probability=True)\n",
    "    clf.fit(lsi_train,train_target)\n",
    "    y_pred_lsi = clf.predict(lsi_test)\n",
    "    print('Accuracy of model =',accuracy_score(y_pred_lsi,test_target))\n",
    "    print('Precision of model =',precision_score(y_pred_lsi,test_target))\n",
    "    print('Recall of model =',recall_score(y_pred_lsi,test_target))\n",
    "    print(classification_report(y_pred_lsi,test_target))\n",
    "    cfm = confusion_matrix(y_pred_lsi,test_target)\n",
    "    y_pred_lsi = clf.predict_proba(lsi_test)\n",
    "    y_prob = [x[1] for x in y_pred_lsi]\n",
    "    fpr, tpr, thresholds = roc_curve(test_target, y_prob, drop_intermediate=False)\n",
    "    plt.plot(fpr,tpr)\n",
    "    save_plot(fig,filename='lsi_svm_'+min_df+'_'+str(C),directory='results/roc')\n",
    "    save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_lsi_svm_'+min_df+'_'+str(C),directory='results/confusion_matrix')\n",
    "\n",
    "    fig=plt.figure()\n",
    "    print('---------------NMF RESULTS---------------')\n",
    "    clf = svm.SVC(kernel='linear',C=C,random_state=42,probability=True)\n",
    "    clf.fit(nmf_train,train_target)\n",
    "    y_pred_nmf = clf.predict(nmf_test)\n",
    "    print('Accuracy of model =',accuracy_score(y_pred_nmf,test_target))\n",
    "    print('Precision of model =',precision_score(y_pred_nmf,test_target))\n",
    "    print('Recall of model =',recall_score(y_pred_nmf,test_target))\n",
    "    print(classification_report(y_pred_nmf,test_target))\n",
    "    cfm = confusion_matrix(y_pred_nmf,test_target)\n",
    "    y_pred_nmf = clf.predict_proba(nmf_test)\n",
    "    y_prob = [x[1] for x in y_pred_nmf]\n",
    "    fpr, tpr, thresholds = roc_curve(test_target, y_prob,drop_intermediate=False)\n",
    "    plt.plot(fpr,tpr)\n",
    "    save_plot(fig,filename='nmf_svm_'+min_df+'_'+str(C),directory='results/roc')\n",
    "    save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_nmf_svm_'+min_df+'_'+str(C),directory='results/confusion_matrix')\n",
    "\n",
    "print('---------------HARD SVM---------------')\n",
    "runSVM(lsi_train,nmf_train,train_target,lsi_test,nmf_test,test_target,C=1000)\n",
    "\n",
    "print('---------------SOFT SVM---------------')\n",
    "runSVM(lsi_train,nmf_train,train_target,lsi_test,nmf_test,test_target,C=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (f) : K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_validation(train_data,train_target,test_data,test_target,typ):\n",
    "    global min_df\n",
    "    tuned_parameters = [{'kernel': ['linear'], 'C': [10**k for k in range(-3,4)]}]\n",
    "    scores = ['accuracy']\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for {0} - {1}\".format(score,typ))\n",
    "        clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=5,\n",
    "                           scoring=score)\n",
    "        clf.fit(train_data, train_target)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print(clf.best_params_)\n",
    "        print(\"Grid scores on development set:\")\n",
    "        for params, mean_score, scores in clf.grid_scores_:\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean_score, scores.std() * 2, params))\n",
    "        print(\"Detailed classification report:\")\n",
    "        y_pred = clf.predict(test_data)\n",
    "        print('Accuracy of model =',accuracy_score(y_pred,test_target))\n",
    "        print('Precision of model =',precision_score(y_pred,test_target))\n",
    "        print('Recall of model =',recall_score(y_pred,test_target))\n",
    "        print(classification_report(y_pred,test_target))\n",
    "        cfm = confusion_matrix(y_pred,test_target)\n",
    "        save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_best_kfold_'+typ+'_'+min_df,directory='results/confusion_matrix')\n",
    "\n",
    "print('LSI')\n",
    "kfold_cross_validation(lsi_train,train_target,lsi_test,test_target,'lsi')\n",
    "print('NMF')\n",
    "kfold_cross_validation(nmf_train,train_target,nmf_test,test_target,'nmf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (g) : Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotROC(y_pred,test_target,filename):\n",
    "    fig = plt.figure()\n",
    "    fpr, tpr, thresholds = roc_curve(test_target, y_pred, drop_intermediate=False)\n",
    "    plt.plot(fpr,tpr)\n",
    "    save_plot(fig,filename,directory='results/roc')\n",
    "\n",
    "print(\"------------------Gaussian Naive Bayes (LSI)------------------\")\n",
    "gnb = GaussianNB()\n",
    "y_pred_lsi = gnb.fit(lsi_train, train_target).predict(lsi_test)\n",
    "print('Accuracy of model =',accuracy_score(y_pred_lsi,test_target))\n",
    "print('Precision of model =',precision_score(y_pred_lsi,test_target))\n",
    "print('Recall of model =',recall_score(y_pred_lsi,test_target))\n",
    "cfm = confusion_matrix(y_pred_lsi,test_target)\n",
    "save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_gaussnb-lsi-'+min_df,directory='results/confusion_matrix')\n",
    "plotROC(y_pred_lsi,test_target,'gaussnb-lsi-'+min_df)\n",
    "\n",
    "print(\"------------------Gaussian Naive Bayes (NMF)------------------\")\n",
    "y_pred_nmf = gnb.fit(nmf_train, train_target).predict(nmf_test)\n",
    "print('Accuracy of model =',accuracy_score(y_pred_nmf,test_target))\n",
    "print('Precision of model =',precision_score(y_pred_nmf,test_target))\n",
    "print('Recall of model =',recall_score(y_pred_nmf,test_target))\n",
    "cfm = confusion_matrix(y_pred_nmf,test_target)\n",
    "save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_gnb-nmf-'+min_df,directory='results/confusion_matrix')\n",
    "plotROC(y_pred_nmf,test_target,'gnb-nmf-'+min_df)\n",
    "\n",
    "print(\"------------------Multinomial Naive Bayes (NMF)------------------\")\n",
    "mnb = MultinomialNB()\n",
    "y_pred = mnb.fit(nmf_train, train_target).predict(nmf_test)\n",
    "print('Accuracy of model =',accuracy_score(y_pred_nmf,test_target))\n",
    "print('Precision of model =',precision_score(y_pred_nmf,test_target))\n",
    "print('Recall of model =',recall_score(y_pred_nmf,test_target))\n",
    "cfm = confusion_matrix(y_pred_nmf,test_target)\n",
    "save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_multinb-nmf-'+min_df,directory='results/confusion_matrix')\n",
    "plotROC(y_pred_nmf,test_target,'multinb-'+min_df)\n",
    "\n",
    "print(\"------------------Bernoulli Naive Bayes (NMF)------------------\")\n",
    "bnb = BernoulliNB()\n",
    "y_pred = bnb.fit(nmf_train, train_target).predict(nmf_test)\n",
    "print('Accuracy of model =',accuracy_score(y_pred_nmf,test_target))\n",
    "print('Precision of model =',precision_score(y_pred_nmf,test_target))\n",
    "print('Recall of model =',recall_score(y_pred_nmf,test_target))\n",
    "cfm = confusion_matrix(y_pred_nmf,test_target)\n",
    "save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_bernoullinb-'+min_df,directory='results/confusion_matrix')\n",
    "plotROC(y_pred_nmf,test_target,'bernoullinb-'+min_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (h) : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(train,train_target,test,test_target,filename,penalty='l2',C=1.0):\n",
    "    logres = LogisticRegression(C=C, penalty=penalty)\n",
    "    y_pred = logres.fit(train,train_target).predict(test)\n",
    "    print('Accuracy of model =',accuracy_score(y_pred,test_target))\n",
    "    print('Precision of model =',precision_score(y_pred,test_target))\n",
    "    print('Recall of model =',recall_score(y_pred,test_target))\n",
    "    cfm = confusion_matrix(y_pred,test_target)\n",
    "    save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_'+filename+'-'+penalty+str(C),directory='results/confusion_matrix')\n",
    "    plotROC(y_pred,test_target,filename+'-'+penalty+str(C))\n",
    "\n",
    "print(\"------------------Logistic Regression (LSI)------------------\")\n",
    "logisticRegression(lsi_train,train_target,lsi_test,test_target,'logres-lsi')\n",
    "\n",
    "print(\"------------------Logistic Regression (NMF)------------------\")\n",
    "logisticRegression(nmf_train,train_target,nmf_test,test_target,'logres-nmf')\n",
    "\n",
    "print(\"------------------Logistic Regression (LSI)------------------\")\n",
    "logisticRegression(lsi_train,train_target,lsi_test,test_target,'logres-lsi',C=.000000001)\n",
    "\n",
    "print(\"------------------Logistic Regression (NMF)------------------\")\n",
    "logisticRegression(nmf_train,train_target,nmf_test,test_target,'logres-nmf',C=.000000001)\n",
    "\n",
    "\n",
    "C = [10**k for k in range(-2,5)]\n",
    "for c in C:\n",
    "    print(\"------------------Logistic Regression (LSI C=\"+str(c)+\")------------------\")\n",
    "    logisticRegression(lsi_train,train_target,lsi_test,test_target,'logres-lsi-'+str(c),C=c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (i) : Regularization for Logistic Regression\n",
    "1. L2 regularization was done in Part (h).\n",
    "2. In this part, we will do L1 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------------Logistic Regression (LSI)------------------\")\n",
    "logisticRegression(lsi_train,train_target,lsi_test,test_target,'logres-lsi-'+min_df,penalty='l1')\n",
    "\n",
    "print(\"------------------Logistic Regression (NMF)------------------\")\n",
    "logisticRegression(nmf_train,train_target,nmf_test,test_target,'logres-nmf-'+min_df,penalty='l1')\n",
    "\n",
    "print(\"------------------Logistic Regression (TFIDF)------------------\")\n",
    "logisticRegression(training_data,train_target,testing_data,test_target,'logres-tfidf',penalty='l1')\n",
    "\n",
    "C = [10**k for k in range(-2,5)]\n",
    "for c in C:\n",
    "    print(\"------------------Logistic Regression (LSI C=\"+str(c)+\")------------------\")\n",
    "    logisticRegression(lsi_train,train_target,lsi_test,test_target,'logres-lsi-'+min_df+str(c),C=c,penalty='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (j) : Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data for multiclass and preprocess it.\n",
    "categories = ['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'misc.forsale','soc.religion.christian']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True,\n",
    "                                  random_state=42, remove=('headers','footers','quotes'))\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True,\n",
    "                                 random_state=42, remove=('headers','footers','quotes'))\n",
    "\n",
    "stemmer,analyzer,vectorizer,tfidf_transformer = initParams(tfidf_min_df=2)\n",
    "training_data = getTfidf(vectorizer,tfidf_transformer,twenty_train.data)\n",
    "training_target = twenty_train.target\n",
    "testing_data = getTfidf(vectorizer,tfidf_transformer,twenty_test.data,isTraining=False)\n",
    "testing_target = twenty_test.target\n",
    "nmf,nmf_train = getNMF(training_data)\n",
    "_,nmf_test = getNMF(testing_data,nmf,isTrain=False)\n",
    "lsi,lsi_train = getLSI(training_data)\n",
    "_,lsi_test = getLSI(testing_data,lsi,isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_names = categories\n",
    "print(\"------------------Bernoulli Naive Bayes------------------\")\n",
    "bnb = BernoulliNB()\n",
    "y_pred = bnb.fit(nmf_train, training_target).predict(nmf_test)\n",
    "print('Accuracy of model =',accuracy_score(y_pred,testing_target))\n",
    "print('Precision of model =',precision_score(y_pred,testing_target, average=None))\n",
    "print('Recall of model =',recall_score(y_pred,testing_target, average=None))\n",
    "print(classification_report(y_pred,testing_target))\n",
    "cfm = confusion_matrix(y_pred,testing_target)\n",
    "save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_multiclass_bnb',directory='results/confusion_matrix')\n",
    "\n",
    "print(\"------------------Gaussian Naive Bayes------------------\")\n",
    "bnb = GaussianNB()\n",
    "y_pred = bnb.fit(nmf_train, training_target).predict(nmf_test)\n",
    "print('Accuracy of model =',accuracy_score(y_pred,testing_target))\n",
    "print('Precision of model =',precision_score(y_pred,testing_target, average=None))\n",
    "print('Recall of model =',recall_score(y_pred,testing_target, average=None))\n",
    "cfm = confusion_matrix(y_pred,testing_target)\n",
    "save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_multiclass_gnb',directory='results/confusion_matrix')\n",
    "\n",
    "print(\"------------------Multinomial Naive Bayes------------------\")\n",
    "bnb = MultinomialNB()\n",
    "y_pred = bnb.fit(nmf_train, training_target).predict(nmf_test)\n",
    "print('Accuracy of model =',accuracy_score(y_pred,testing_target))\n",
    "print('Accuracy of model =',accuracy_score(y_pred,testing_target))\n",
    "print('Precision of model =',precision_score(y_pred,testing_target, average=None))\n",
    "print('Recall of model =',recall_score(y_pred,testing_target, average=None))\n",
    "cfm = confusion_matrix(y_pred,testing_target)\n",
    "save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_multiclass_mnb',directory='results/confusion_matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass SVM (One vs One)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo_svc = OneVsOneClassifier(svm.SVC(kernel='linear',C=1000, random_state=42)).fit(lsi_train, training_target)\n",
    "y_pred = ovo_svc.predict(lsi_test)\n",
    "print('Accuracy of model =',accuracy_score(y_pred,testing_target))\n",
    "print('Precision of model =',precision_score(y_pred,testing_target, average=None))\n",
    "print('Recall of model =',recall_score(y_pred,testing_target, average=None))\n",
    "cfm = confusion_matrix(y_pred,testing_target)\n",
    "save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_multiclass_ovo_lsi',directory='results/confusion_matrix')\n",
    "\n",
    "ovo_svc = OneVsOneClassifier(svm.SVC(kernel='linear',C=1000, random_state=42)).fit(nmf_train, training_target)\n",
    "y_pred = ovo_svc.predict(nmf_test)\n",
    "print('Accuracy of model =',accuracy_score(y_pred,testing_target))\n",
    "print('Precision of model =',precision_score(y_pred,testing_target, average=None))\n",
    "print('Recall of model =',recall_score(y_pred,testing_target, average=None))\n",
    "\n",
    "cfm = confusion_matrix(y_pred,testing_target)\n",
    "save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_multiclass_ovo_nmf',directory='results/confusion_matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass SVM (One vs Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_svc = OneVsRestClassifier(svm.SVC(kernel='linear',C=1000, random_state=42)).fit(lsi_train, training_target)\n",
    "y_pred = ovr_svc.predict(lsi_test)\n",
    "print('Accuracy of model =',accuracy_score(y_pred,testing_target))\n",
    "print('Precision of model =',precision_score(y_pred,testing_target, average=None))\n",
    "print('Recall of model =',recall_score(y_pred,testing_target, average=None))\n",
    "cfm = confusion_matrix(y_pred,testing_target)\n",
    "save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_multiclass_ovr_lsi',directory='results/confusion_matrix')\n",
    "\n",
    "ovr_svc = OneVsRestClassifier(svm.SVC(kernel='linear',C=1000, random_state=42)).fit(nmf_train, training_target)\n",
    "y_pred = ovr_svc.predict(nmf_test)\n",
    "print('Accuracy of model =',accuracy_score(y_pred,testing_target))\n",
    "print('Precision of model =',precision_score(y_pred,testing_target, average=None))\n",
    "print('Recall of model =',recall_score(y_pred,testing_target, average=None))\n",
    "cfm = confusion_matrix(y_pred,testing_target)\n",
    "save_plot(plot_confusion_matrix(cfm,target_names),\n",
    "              filename='cfm_multiclass_ovr_nmf',directory='results/confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
