{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score,log_loss\n",
    "from sklearn.metrics import roc_curve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import save,load,save_plot,plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (1) : Building TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data ==> 4732\n",
      "Length of testing data ==> 3150\n"
     ]
    }
   ],
   "source": [
    "categories = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "              'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True,\n",
    "                                  random_state=42, remove=('headers','footers','quotes'))\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True,\n",
    "                                 random_state=42, remove=('headers','footers','quotes'))\n",
    "print(\"Length of training data ==>\", len(twenty_train.data))\n",
    "print(\"Length of testing data ==>\", len(twenty_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Report Dimensions:---------------\n",
      "Shape of Training Data ==> (4732, 12113)\n",
      "Shape of Testing Data ==> (3150, 12113)\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def initParams(tfidf_min_df):\n",
    "    analyzer = CountVectorizer().build_analyzer()\n",
    "    #Use token_pattern parameter with analyzer='word' if no stemming and want to remove words that are only numbers.\n",
    "    vectorizer = CountVectorizer(stop_words='english', min_df=tfidf_min_df, max_df=0.8, analyzer=\"word\",\n",
    "                                 strip_accents='ascii', token_pattern='\\w*[a-zA-Z]')\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    return [analyzer,vectorizer,tfidf_transformer]\n",
    "\n",
    "def getTfidf(vectorizer,tfidf_transformer,data,isTraining=True):\n",
    "    if(isTraining):\n",
    "        count_data = vectorizer.fit_transform(data)\n",
    "        tfidf_data = tfidf_transformer.fit_transform(count_data)\n",
    "    else:\n",
    "        count_data = vectorizer.transform(data)\n",
    "        tfidf_data = tfidf_transformer.transform(count_data)        \n",
    "    return tfidf_data\n",
    "\n",
    "\n",
    "analyzer,vectorizer,tfidf_transformer = initParams(tfidf_min_df=3)\n",
    "\n",
    "load_from_previous = True\n",
    "\n",
    "if(load_from_previous):\n",
    "    training_data = load('tfidf_training')\n",
    "    testing_data = load('tfidf_testing')\n",
    "else:\n",
    "    training_data = getTfidf(vectorizer,tfidf_transformer,twenty_train.data)\n",
    "    testing_data = getTfidf(vectorizer,tfidf_transformer,twenty_test.data,isTraining=False)\n",
    "    save(training_data,'tfidf_training')\n",
    "    save(testing_data,'tfidf_testing')\n",
    "print('---------------Report Dimensions:---------------')\n",
    "print('Shape of Training Data ==>', training_data.shape)\n",
    "print('Shape of Testing Data ==>', testing_data.shape)\n",
    "print('------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART(2): Applying k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bench_k_means(estimator, name, data):\n",
    "    t0 = time()\n",
    "    estimator.fit(data)\n",
    "    print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "          % (name, (time() - t0), estimator.inertia_,\n",
    "             metrics.homogeneity_score(labels, estimator.labels_),\n",
    "             metrics.completeness_score(labels, estimator.labels_),\n",
    "             metrics.v_measure_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=None)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4732,)\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', \n",
    "                verbose=0, random_state=42, copy_x=True, n_jobs=1, algorithm='auto')\n",
    "rnd = KMeans(n_clusters=k, init='random', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', \n",
    "                verbose=0, random_state=42, copy_x=True, n_jobs=1, algorithm='auto')\n",
    "#kmeans.fit(training_data)\n",
    "#res = kmeans.predict(testing_data)\n",
    "#res.shape\n",
    "labels = list((map(lambda x : 0 if x<4 else 1,twenty_train.target)))\n",
    "labels = np.array(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________\n",
      "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "k-means++\t42.88s\t4487\t0.422\t0.455\t0.438\t0.444\t0.422\t0.010\n",
      "k-means++\t37.84s\t4487\t0.458\t0.484\t0.471\t0.493\t0.458\t0.009\n"
     ]
    }
   ],
   "source": [
    "print(82 * '_')\n",
    "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "\n",
    "bench_k_means(kmeans, 'k-means++', training_data)\n",
    "bench_k_means(rnd, 'k-means++', training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(res)):\n",
    "    print(labels[i], res[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
